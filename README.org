#+TITLE: K8S the hard way KVM

* Setup

* Install the client tools

** Certificates

Certificate management tooling:

#+begin_src sh
wget -q --show-progress --https-only --timestamping \
  https://storage.googleapis.com/kubernetes-the-hard-way/cfssl/1.4.1/linux/cfssl \
  https://storage.googleapis.com/kubernetes-the-hard-way/cfssl/1.4.1/linux/cfssljson

chmod +x ./cfssl
chmod +x ./cfssljson
#+end_src

** Kubectl

=Kubectl= is assumed to already be installed.

** KCLI

To provision the infrastructure resources instead of using =glcoud= this will
use =kcli= to bring up machines on the lokal desktop:

#+begin_src sh
sudo dnf -y copr enable karmab/kcli
sudo dnf -y install kcli
#+end_src
* Provisiong the compute resources

** Configure kcli

First the local endpoint must be configured to be used by =kcli= as well as the
the =default= storage pool and a =network= to be used by the machines:

#+begin_src sh
kcli create host -H 127.0.0.1 local

kcli create pool -p /var/lib/libvirt/images default
# Optionally allow the currently logged in used to access this pool of images:
sudo setfacl -m u:$(id -un):rwx /var/lib/libvirt/images

kcli create network -c 10.192.0.0/24 --domain k8s.thw.local k8s-thw
#+end_src

Firewall rules don't need to be configured as the communication between host and
machines inside the same network is allowed by default.

To be able to boot the machines a =cloud-image= is needed - in this case Ubuntu
20.04:

#+begin_src sh
kcli download image ubuntu2004 --pool default
#+end_src

Booting the required machines can be done using a =yaml= definition file for profiles.
The file needs to be stored in =~/.kcli/profiles=

#+begin_src yaml :tangle yes
local_ubuntu2004:
  image: focal-server-cloudimg-amd64.img

loadbalancer:
  image: focal-server-cloudimg-amd64.img
  numcpus: 1
  memory: 512
  disk:
    - size: 10
  nets:
    - k8s-thw
  reservedns: True
  reserveip: True
  reservehost: True

node:
  image: focal-server-cloudimg-amd64.img
  numcpus: 2
  memory: 1024
  disk:
    - size: 10
  nets:
    - k8s-thw
  reservedns: True
  reserveip: True
  reservehost: True
#+end_src

Starting the nodes can now be achieved in a simple loop:

- This will start 3 masters and 3 workers

#+begin_src sh
for node in master00 master01 master02; do
    kcli create vm --profile node ${node}
done
#+end_src

#+begin_src sh
for node in worker00 worker01 worker03; do
    kcli create vm --profile node ${node}
done
#+end_src

And deploy a single loadbalancer for the master nodes that will run =HAProxy=:

#+begin_src sh
kcli create vm --profile loadbalancer lb
#+end_src

The configuration for the loadbalancer will be as follows:

#+NAME: domain
#+begin_src sh
echo k8s.thw.local
#+end_src


#+NAME: ip
#+begin_src sh :noweb yes :var fqdn="master00"
kcli ssh $fqdn dig +short $fqdn.<<domain()>>
#+end_src

#+begin_src conf :noweb yes :tangle haproxy.cfg
global
        log /dev/log    local0
        log /dev/log    local1 notice
        chroot /var/lib/haproxy
        stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners
        stats timeout 30s
        user haproxy
        group haproxy
        daemon

        # Default SSL material locations
        ca-base /etc/ssl/certs
        crt-base /etc/ssl/private

        # See: https://ssl-config.mozilla.org/#server=haproxy&server-version=2.0.3&config=intermediate
        ssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384
        ssl-default-bind-ciphersuites TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256
        ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets

defaults
        log     global
        mode    http
        option  httplog
        option  dontlognull
        timeout connect 5000
        timeout client  50000
        timeout server  50000
        errorfile 400 /etc/haproxy/errors/400.http
        errorfile 403 /etc/haproxy/errors/403.http
        errorfile 408 /etc/haproxy/errors/408.http
        errorfile 500 /etc/haproxy/errors/500.http
        errorfile 502 /etc/haproxy/errors/502.http
        errorfile 503 /etc/haproxy/errors/503.http
        errorfile 504 /etc/haproxy/errors/504.http

frontend  main
    bind *:6443
    mode tcp
    default_backend mgmt6443
    option tcplog

backend mgmt6443
    balance source
    mode tcp
    # MASTERS 6443
    server master00.<<domain()>> <<ip(fqdn='master00')>>:6443 check
    server master01.<<domain()>> <<ip(fqdn='master01')>>:6443 check
    server master02.<<domain()>> <<ip(fqdn='master02')>>:6443 check
#+end_src
